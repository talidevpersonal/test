Technical Specification Design (TSD) and Resilience Plan for Customer‑Portal Document Upload Service
Last updated: 1 August 2025 (Asia/Dubai time)

1 Overview
The customer portal allows customers to upload regulatory documents (e.g., trade licence, passport, Emirates ID) when submitting requests. A document upload service stores the documents in a local database, then asynchronously uploads them to a document cloud service (referred to in the notes as) and finally posts document locations to a request‑for‑information (RFI) API. The user should see a “success” message as soon as the file is stored locally; cloud uploads happen in the background with automatic retries.

The following TSD covers functional requirements, data models, interface definitions and the asynchronous processing workflow. A resilience plan describes how the system deals with transient faults, network failures and other edge cases, using retry patterns and idempotent operations.

2 Functional requirements
2.1 User‑facing requirements
Document categories: The document upload screen lists multiple categories (trade licence, passport, etc.). Each category has its own requirements (e.g., file type, size) and status. Customers may upload a document for each category or reuse previously stored documents.

Immediate acknowledgement: When a document is uploaded to the local database, the service returns a successful response. Users should not be forced to wait for the file to be transferred to the cloud.

Status tracking: The user interface displays the list of documents with their statuses (Pending, Uploading, Uploaded, Failed) and allows replacement of failed documents. A checklist marks which required categories have successfully uploaded documents.

Security and validation: The service must validate file type, size and content. Files should be virus‑scanned and encrypted at rest. Only authenticated customers may upload documents.

2.2 Backend requirements
Local persistence: Uploaded files must be stored in a database (or a local file store) with metadata before being sent to the cloud. Each document record includes a unique identifier, category, customer reference, status and cloud location once available.

Asynchronous upload: A background job picks up documents with status Pending or UploadFailed, attempts to upload them to the cloud, and updates the status and cloud location in the local database. The job must not block user requests.

Integration with RFI API: Once a document is uploaded to the cloud, the background job posts the document’s cloud location to the RFI API. This API call should be idempotent to avoid duplicate requests in case of retries.

Logging and audit: All operations (upload attempts, successes, failures and RFI notifications) must be logged. Early failures should be recorded as informational events and only the final failed attempt should generate an error report
learn.microsoft.com
.

3 High‑level architecture
3.1 Components
Component	Description
Document Screen (UI)	Web/mobile interface where customers select categories and upload files. Sends requests to the BFF layer.
BFF (Backend for Frontend)	API layer that authenticates the user, performs validations, stores documents in the local database and returns immediate success responses. Also exposes endpoints to list documents and statuses.
Local Database/File Store	Stores document metadata and the binary file (or a pointer to a file store) with statuses. Also holds category definitions and a log of upload attempts.
Document Cloud Service (Maktaba)	External storage service for long‑term retention of documents. Provides an API to upload files and returns a location/URL for each uploaded file.
RFI API	Request‑for‑information API that receives the list of cloud document locations associated with a customer request. Should be idempotent and handle duplicate submissions gracefully.
Background Job / Worker	Asynchronous process that uploads pending documents to the cloud, updates local status, and invokes the RFI API. Runs either on a schedule or triggered by new uploads.

3.2 Data flow
Upload request: The UI calls POST /documents with a multipart upload containing the file and metadata (customer ID, category). The BFF validates the input (file size/type) and stores the file in the local database with status Pending. It returns success to the user.

Event creation: The BFF sends a message to a queue or marks the document as Pending in the database. This acts as an event‑driven trigger for the background job
learn.microsoft.com
.

Background processing: A worker listens for new events or periodically polls the database. For each pending document it:

Reads the file and metadata from local storage.

Attempts to upload the file to the document cloud service via its API. If the upload fails due to transient faults (network hiccup or service throttling), it retries using an exponential backoff with jitter
dev.to
. If the failure is non‑transient (e.g., invalid credentials), the status is set to UploadFailed without retries.

Upon success, it updates the document status to Uploaded, saves the cloud location/URL and any cloud document ID in the database.

It invokes the RFI API with the document location(s). This call must include a unique idempotency key (e.g., the local document ID and a timestamp) so that repeated calls with the same key do not create duplicate entries
internetcomputer.org
.

On failure of the RFI call, the worker uses the same retry pattern. After maximum attempts, it records a failure and raises an alert.

Status update: The UI can query GET /documents to display document statuses. A separate endpoint can be provided to retry failed uploads manually.

3.3 Deployment considerations
Scalability: The BFF and worker should be stateless and horizontally scalable. Use a load balancer or API gateway. The local storage could be a relational DB with BLOB support or an object storage service with metadata in a relational table.

Hosting: Background jobs can run as a scheduled task or as an event‑driven worker. Azure WebJobs or Functions, a Kubernetes CronJob, or a managed message queue consumer can be used. Event‑driven triggers (queue messages) are recommended to start the job as soon as documents are uploaded
learn.microsoft.com
.

Security: All communications must use HTTPS. Stored files must be encrypted at rest. Access to the local database and document cloud credentials should be secured with role‑based access control and secret management. The UI should require authentication (e.g., OAuth).

4 Data model
4.1 Entities
Table / Entity	Key fields	Notes
Customer	customer_id, name, email, etc.	Basic customer data.
DocumentCategory	category_id, name, description, required	Defines categories (e.g., Trade Licence, Passport).
Document	document_id, customer_id, category_id, file_path, status, cloud_location, document_id_cloud, attempt_count, last_attempt_at, created_at, updated_at	Stores the binary file (via file_path), status (Pending, Uploading, Uploaded, UploadFailed), attempt count, and the cloud location once uploaded.
UploadAttemptLog	log_id, document_id, timestamp, status, error_message	Records every upload attempt. Early failures should be logged as informational events and only the final failure should be logged as an error
learn.microsoft.com
.

4.2 Status values
Pending – file stored locally, waiting to be uploaded.

Uploading – worker is attempting to upload the file.

Uploaded – file successfully uploaded to the cloud, cloud_location populated.

UploadFailed – all retry attempts exhausted, manual intervention required.

5 API specification (BFF layer)
5.1 Upload document
bash
Copy
Edit
POST /documents
Content-Type: multipart/form-data

Parameters:
  customer_id    – ID of the customer.
  category_id    – ID of the document category.
  file           – binary file.

Response (201 Created):
{
  "document_id": "uuid",
  "status": "Pending"
}

Errors:
  400 Bad Request – invalid file type, size or missing parameters.
  401 Unauthorized – authentication failed.
  500 Internal Server Error – unexpected error storing the file.
5.2 List documents
bash
Copy
Edit
GET /documents?customer_id={id}

Response (200 OK):
[
  {
    "document_id": "uuid",
    "category": "TradeLicence",
    "status": "Uploaded",
    "cloud_location": "https://cloudservice/documents/..."
  },
  ...
]
5.3 Retry failed document (optional)
bash
Copy
Edit
POST /documents/{document_id}/retry

Triggers the worker to retry uploading a document marked as UploadFailed.
6 Background job design
6.1 Triggering mechanisms
Event‑driven approach: When the BFF stores a document with status Pending, it publishes a message (e.g., to Azure Queue Storage or RabbitMQ). A worker listens on the queue. The Azure architecture guidance recommends event‑driven triggers where the UI places a message in a queue and the background task reads it
learn.microsoft.com
. This decouples the upload process and avoids polling.

Schedule‑driven approach: Alternatively, a scheduler runs at fixed intervals (e.g., every 5 minutes) and scans the database for documents with status Pending or UploadFailed
learn.microsoft.com
. This is simpler but introduces latency and must handle idempotency because multiple scheduler instances could run concurrently
learn.microsoft.com
.

6.2 Retry strategy
Retry pattern: Transient faults such as network timeouts or service throttling should be handled using a retry policy. Microsoft’s retry pattern advises using either immediate retries, delayed retries or a combination
learn.microsoft.com
. For most cloud uploads, a delayed retry with exponential backoff is appropriate. Increase the delay between attempts (e.g., 2 s → 4 s → 8 s) and introduce jitter (randomisation) to avoid synchronized bursts
dev.to
.

Max attempts: Define a maximum number of retry attempts (e.g., 3–5). After that, mark the document as UploadFailed and log the error. The user can then manually retry.

Selective retry: Only retry on transient exceptions (timeouts, 5xx errors). Do not retry on validation errors or permanent failures (e.g., “File too large”)
dev.to
.

Batched operations: When processing multiple documents, limit concurrency and process uploads in small batches. The Barstool engineering report recommends uploading files in batches and setting a maximum concurrency to avoid overloading the API
barstool.engineering
. Each batch can use retry logic per file.

Dead‑letter queue: For documents where retries are exhausted, move the message/document ID to a dead‑letter queue for manual review.

Idempotency: Ensure the cloud upload and RFI API calls are idempotent. Assign unique identifiers to each upload (e.g., document_id) and send them as idempotency keys. Idempotent endpoints guarantee that repeating a call produces the same result, enabling safe retries
internetcomputer.org
.

6.3 Logging and monitoring
Informational vs error logging: According to Microsoft’s retry guidance, early failures should be logged as informational entries, while only the final failure after all retries should be logged as an error
learn.microsoft.com
. This prevents alert fatigue.

Metrics: Track metrics such as average upload time, retry counts, failure rates and queue lengths. Export these metrics to a monitoring system (e.g., Prometheus, Azure Monitor) to alert operations when thresholds are exceeded.

Audit trail: Store an audit log of upload attempts (UploadAttemptLog) with timestamps, statuses and error messages. This helps troubleshoot issues and satisfy regulatory requirements.

6.4 Status communication
Because background tasks run out‑of‑band, the UI cannot rely on immediate results. The Azure guidance suggests that if the UI needs progress information, the background task should update a status value in storage or send messages back on a reply queue
learn.microsoft.com
. In this design the worker updates the document status in the database; the UI periodically queries the list of documents to refresh statuses.

7 Resilience plan
7.1 Potential failure points
Database failure: The local database may be unavailable or slow. Use a managed database with high availability. The BFF should implement connection pooling and retry strategies for transient database failures. If the database is down, the service should return an error and instruct the user to try again later.

File storage failure: If the local file store is full or inaccessible, the upload must fail gracefully. Monitor disk usage and set alerts. Consider storing files in an object storage service that provides redundancy.

Network issues: Uploading to the cloud or posting to the RFI API may fail due to network problems or throttling. Use the retry pattern described above, with exponential backoff and jitter
dev.to
.

Cloud service outage: The document cloud may be temporarily unavailable. Transient faults should be retried; after repeated failures, the document remains in UploadFailed status. Operators can replay failed tasks once the cloud is available.

Duplicate requests: Without idempotency, retries could cause duplicate documents or duplicate calls to the RFI API. Use unique idempotency keys and deduplication to ensure that repeated calls have no side effects
internetcomputer.org
. Sequence numbers or unique IDs can provide deduplication.

Concurrent scheduler instances: If using a schedule‑driven job, multiple instances might pick up the same document. To avoid duplicate uploads, implement a locking mechanism (e.g., update the status to Uploading with a timestamp and ensure only one worker processes a document at a time) and design the upload process to be idempotent.

Large file uploads: Very large documents may exceed API limits. Consider using multipart upload (e.g., S3 multi‑part). The Barstool engineering article shows how they used multi‑part uploads and concurrency limits
barstool.engineering
.

7.2 Mitigation strategies
Use event‑driven triggers: Post a message to a queue when a document is uploaded locally. This decouples the UI from the background job and ensures timely processing
learn.microsoft.com
.

Apply exponential backoff with jitter: For transient errors, retry after increasing delays with randomisation. Avoid fixed delays that can cause bursts of retries and overload the service
dev.to
.

Classify errors: Determine whether an error is transient or permanent. Only transient errors should trigger retries
dev.to
.

Implement idempotent endpoints: Include unique identifiers in cloud upload and RFI API calls to ensure repeated calls have the same effect
internetcomputer.org
.

Limit concurrency: Process uploads in batches with a defined maximum concurrency to avoid exceeding API limits and to prevent the entire batch from failing due to one file
barstool.engineering
.

Dead‑letter queue: After maximum retries, move failed tasks to a dead‑letter queue for manual inspection and resolution.

Monitoring and alerting: Use metrics and logs to detect unusual error rates. Set up alerts on high failure rates, long queue lengths or repeated UploadFailed statuses.

Manual retry / self‑service: Provide an endpoint that allows the customer or support staff to manually retry uploads for documents in UploadFailed status. Manual retries should still honour idempotency and should not duplicate uploads.

7.3 Testing and validation
Unit tests: Validate the BFF logic (file validation, metadata persistence). Mock the cloud service and RFI API to test failure scenarios and retry logic.

Integration tests: Simulate network failures, slow responses and cloud outages. Verify that the background job handles retries correctly and does not lose data.

Load tests: Upload multiple files concurrently to ensure the system scales. Evaluate the effect of concurrency limits and batching on performance.

Security tests: Perform penetration tests on file uploads to ensure proper sanitisation and that malicious files cannot be executed. Verify encryption of data at rest and in transit.

8 Additional considerations
Data retention and compliance: Documents may contain personally identifiable information (PII). Implement retention policies, anonymisation where appropriate and secure deletion after the retention period. Ensure compliance with UAE regulations such as Dubai’s Data Protection Law.

Localization and accessibility: Ensure the UI supports multiple languages and is accessible to users with disabilities. Provide clear error messages when uploads fail.

Extensibility: Design the system so that new document categories can be added without code changes. Use configuration tables to define which categories are required and what validations apply.

9 Conclusion
This TSD defines a document upload service for the customer portal with a robust, asynchronous design. Documents are stored locally and later uploaded to a cloud service via an event‑driven background job. The resilience plan applies retry patterns with exponential backoff and jitter
dev.to
, idempotent operations
internetcomputer.org
, concurrency limits
barstool.engineering
 and proper logging
learn.microsoft.com
 to handle transient faults and ensure data integrity. With proper monitoring, security and regulatory compliance, the service will provide a reliable user experience even under adverse conditions.



This report provides an in-depth architecture, data model, API specification and a detailed resilience strategy with citations from reliable sources. Let me know if you need modifications or further details!






Sources






You said:
Give me download link for thiscplan



2/2

ChatGPT said:

Stopped after 6 seconds

Stopped after 8 seconds

Worked for 6 seconds
I received your request. I'll provide the download link for the plan shortly.

Here’s the download link for your plan:

Technical Specification Design (TSD) and Resilience Plan for Customer‑Portal Document Upload Service
Last updated: 1 August 2025 (Asia/Dubai time)

1 Overview
The customer portal allows customers to upload regulatory documents (e.g., trade licence, passport, Emirates ID) when submitting requests. A document upload service stores the documents in a local database, then asynchronously uploads them to a document cloud service (referred to in the notes as Maktaba) and finally posts document locations to a request‑for‑information (RFI) API. The user should see a “success” message as soon as the file is stored locally; cloud uploads happen in the background with automatic retries.

The following TSD covers functional requirements, data models, interface definitions and the asynchronous processing workflow. A resilience plan describes how the system deals with transient faults, network failures and other edge cases, using retry patterns and idempotent operations.

2 Functional requirements
2.1 User‑facing requirements
Document categories: The document upload screen lists multiple categories (trade licence, passport, etc.). Each category has its own requirements (e.g., file type, size) and status. Customers may upload a document for each category or reuse previously stored documents.

Immediate acknowledgement: When a document is uploaded to the local database, the service returns a successful response. Users should not be forced to wait for the file to be transferred to the cloud.

Status tracking: The user interface displays the list of documents with their statuses (Pending, Uploading, Uploaded, Failed) and allows replacement of failed documents. A checklist marks which required categories have successfully uploaded documents.

Security and validation: The service must validate file type, size and content. Files should be virus‑scanned and encrypted at rest. Only authenticated customers may upload documents.

2.2 Backend requirements
Local persistence: Uploaded files must be stored in a database (or a local file store) with metadata before being sent to the cloud. Each document record includes a unique identifier, category, customer reference, status and cloud location once available.

Asynchronous upload: A background job picks up documents with status Pending or UploadFailed, attempts to upload them to the cloud, and updates the status and cloud location in the local database. The job must not block user requests.

Integration with RFI API: Once a document is uploaded to the cloud, the background job posts the document’s cloud location to the RFI API. This API call should be idempotent to avoid duplicate requests in case of retries.

Logging and audit: All operations (upload attempts, successes, failures and RFI notifications) must be logged. Early failures should be recorded as informational events and only the final failed attempt should generate an error report
learn.microsoft.com
.

3 High‑level architecture
3.1 Components
Component	Description
Document Screen (UI)	Web/mobile interface where customers select categories and upload files. Sends requests to the BFF layer.
BFF (Backend for Frontend)	API layer that authenticates the user, performs validations, stores documents in the local database and returns immediate success responses. Also exposes endpoints to list documents and statuses.
Local Database/File Store	Stores document metadata and the binary file (or a pointer to a file store) with statuses. Also holds category definitions and a log of upload attempts.
Document Cloud Service (Maktaba)	External storage service for long‑term retention of documents. Provides an API to upload files and returns a location/URL for each uploaded file.
RFI API	Request‑for‑information API that receives the list of cloud document locations associated with a customer request. Should be idempotent and handle duplicate submissions gracefully.
Background Job / Worker	Asynchronous process that uploads pending documents to the cloud, updates local status, and invokes the RFI API. Runs either on a schedule or triggered by new uploads.

3.2 Data flow
Upload request: The UI calls POST /documents with a multipart upload containing the file and metadata (customer ID, category). The BFF validates the input (file size/type) and stores the file in the local database with status Pending. It returns success to the user.

Event creation: The BFF sends a message to a queue or marks the document as Pending in the database. This acts as an event‑driven trigger for the background job
learn.microsoft.com
.

Background processing: A worker listens for new events or periodically polls the database. For each pending document it:

Reads the file and metadata from local storage.

Attempts to upload the file to the document cloud service via its API. If the upload fails due to transient faults (network hiccup or service throttling), it retries using an exponential backoff with jitter
dev.to
. If the failure is non‑transient (e.g., invalid credentials), the status is set to UploadFailed without retries.

Upon success, it updates the document status to Uploaded, saves the cloud location/URL and any cloud document ID in the database.

It invokes the RFI API with the document location(s). This call must include a unique idempotency key (e.g., the local document ID and a timestamp) so that repeated calls with the same key do not create duplicate entries
internetcomputer.org
.

On failure of the RFI call, the worker uses the same retry pattern. After maximum attempts, it records a failure and raises an alert.

Status update: The UI can query GET /documents to display document statuses. A separate endpoint can be provided to retry failed uploads manually.

3.3 Deployment considerations
Scalability: The BFF and worker should be stateless and horizontally scalable. Use a load balancer or API gateway. The local storage could be a relational DB with BLOB support or an object storage service with metadata in a relational table.

Hosting: Background jobs can run as a scheduled task or as an event‑driven worker. Azure WebJobs or Functions, a Kubernetes CronJob, or a managed message queue consumer can be used. Event‑driven triggers (queue messages) are recommended to start the job as soon as documents are uploaded
learn.microsoft.com
.

Security: All communications must use HTTPS. Stored files must be encrypted at rest. Access to the local database and document cloud credentials should be secured with role‑based access control and secret management. The UI should require authentication (e.g., OAuth).

4 Data model
4.1 Entities
Table / Entity	Key fields	Notes
Customer	customer_id, name, email, etc.	Basic customer data.
DocumentCategory	category_id, name, description, required	Defines categories (e.g., Trade Licence, Passport).
Document	document_id, customer_id, category_id, file_path, status, cloud_location, document_id_cloud, attempt_count, last_attempt_at, created_at, updated_at	Stores the binary file (via file_path), status (Pending, Uploading, Uploaded, UploadFailed), attempt count, and the cloud location once uploaded.
UploadAttemptLog	log_id, document_id, timestamp, status, error_message	Records every upload attempt. Early failures should be logged as informational events and only the final failure should be logged as an error
learn.microsoft.com
.

4.2 Status values
Pending – file stored locally, waiting to be uploaded.

Uploading – worker is attempting to upload the file.

Uploaded – file successfully uploaded to the cloud, cloud_location populated.

UploadFailed – all retry attempts exhausted, manual intervention required.

5 API specification (BFF layer)
5.1 Upload document
bash
Copy
Edit
POST /documents
Content-Type: multipart/form-data

Parameters:
  customer_id    – ID of the customer.
  category_id    – ID of the document category.
  file           – binary file.

Response (201 Created):
{
  "document_id": "uuid",
  "status": "Pending"
}

Errors:
  400 Bad Request – invalid file type, size or missing parameters.
  401 Unauthorized – authentication failed.
  500 Internal Server Error – unexpected error storing the file.
5.2 List documents
bash
Copy
Edit
GET /documents?customer_id={id}

Response (200 OK):
[
  {
    "document_id": "uuid",
    "category": "TradeLicence",
    "status": "Uploaded",
    "cloud_location": "https://cloudservice/documents/..."
  },
  ...
]
5.3 Retry failed document (optional)
bash
Copy
Edit
POST /documents/{document_id}/retry

Triggers the worker to retry uploading a document marked as UploadFailed.
6 Background job design
6.1 Triggering mechanisms
Event‑driven approach: When the BFF stores a document with status Pending, it publishes a message (e.g., to Azure Queue Storage or RabbitMQ). A worker listens on the queue. The Azure architecture guidance recommends event‑driven triggers where the UI places a message in a queue and the background task reads it
learn.microsoft.com
. This decouples the upload process and avoids polling.

Schedule‑driven approach: Alternatively, a scheduler runs at fixed intervals (e.g., every 5 minutes) and scans the database for documents with status Pending or UploadFailed
learn.microsoft.com
. This is simpler but introduces latency and must handle idempotency because multiple scheduler instances could run concurrently
learn.microsoft.com
.

6.2 Retry strategy
Retry pattern: Transient faults such as network timeouts or service throttling should be handled using a retry policy. Microsoft’s retry pattern advises using either immediate retries, delayed retries or a combination
learn.microsoft.com
. For most cloud uploads, a delayed retry with exponential backoff is appropriate. Increase the delay between attempts (e.g., 2 s → 4 s → 8 s) and introduce jitter (randomisation) to avoid synchronized bursts
dev.to
.

Max attempts: Define a maximum number of retry attempts (e.g., 3–5). After that, mark the document as UploadFailed and log the error. The user can then manually retry.

Selective retry: Only retry on transient exceptions (timeouts, 5xx errors). Do not retry on validation errors or permanent failures (e.g., “File too large”)
dev.to
.

Batched operations: When processing multiple documents, limit concurrency and process uploads in small batches. The Barstool engineering report recommends uploading files in batches and setting a maximum concurrency to avoid overloading the API
barstool.engineering
. Each batch can use retry logic per file.

Dead‑letter queue: For documents where retries are exhausted, move the message/document ID to a dead‑letter queue for manual review.

Idempotency: Ensure the cloud upload and RFI API calls are idempotent. Assign unique identifiers to each upload (e.g., document_id) and send them as idempotency keys. Idempotent endpoints guarantee that repeating a call produces the same result, enabling safe retries
internetcomputer.org
.

6.3 Logging and monitoring
Informational vs error logging: According to Microsoft’s retry guidance, early failures should be logged as informational entries, while only the final failure after all retries should be logged as an error
learn.microsoft.com
. This prevents alert fatigue.

Metrics: Track metrics such as average upload time, retry counts, failure rates and queue lengths. Export these metrics to a monitoring system (e.g., Prometheus, Azure Monitor) to alert operations when thresholds are exceeded.

Audit trail: Store an audit log of upload attempts (UploadAttemptLog) with timestamps, statuses and error messages. This helps troubleshoot issues and satisfy regulatory requirements.

6.4 Status communication
Because background tasks run out‑of‑band, the UI cannot rely on immediate results. The Azure guidance suggests that if the UI needs progress information, the background task should update a status value in storage or send messages back on a reply queue
learn.microsoft.com
. In this design the worker updates the document status in the database; the UI periodically queries the list of documents to refresh statuses.

7 Resilience plan
7.1 Potential failure points
Database failure: The local database may be unavailable or slow. Use a managed database with high availability. The BFF should implement connection pooling and retry strategies for transient database failures. If the database is down, the service should return an error and instruct the user to try again later.

File storage failure: If the local file store is full or inaccessible, the upload must fail gracefully. Monitor disk usage and set alerts. Consider storing files in an object storage service that provides redundancy.

Network issues: Uploading to the cloud or posting to the RFI API may fail due to network problems or throttling. Use the retry pattern described above, with exponential backoff and jitter
dev.to
.

Cloud service outage: The document cloud may be temporarily unavailable. Transient faults should be retried; after repeated failures, the document remains in UploadFailed status. Operators can replay failed tasks once the cloud is available.

Duplicate requests: Without idempotency, retries could cause duplicate documents or duplicate calls to the RFI API. Use unique idempotency keys and deduplication to ensure that repeated calls have no side effects
internetcomputer.org
. Sequence numbers or unique IDs can provide deduplication.

Concurrent scheduler instances: If using a schedule‑driven job, multiple instances might pick up the same document. To avoid duplicate uploads, implement a locking mechanism (e.g., update the status to Uploading with a timestamp and ensure only one worker processes a document at a time) and design the upload process to be idempotent.

Large file uploads: Very large documents may exceed API limits. Consider using multipart upload (e.g., S3 multi‑part). The Barstool engineering article shows how they used multi‑part uploads and concurrency limits
barstool.engineering
.

7.2 Mitigation strategies
Use event‑driven triggers: Post a message to a queue when a document is uploaded locally. This decouples the UI from the background job and ensures timely processing
learn.microsoft.com
.

Apply exponential backoff with jitter: For transient errors, retry after increasing delays with randomisation. Avoid fixed delays that can cause bursts of retries and overload the service
dev.to
.

Classify errors: Determine whether an error is transient or permanent. Only transient errors should trigger retries
dev.to
.

Implement idempotent endpoints: Include unique identifiers in cloud upload and RFI API calls to ensure repeated calls have the same effect
internetcomputer.org
.

Limit concurrency: Process uploads in batches with a defined maximum concurrency to avoid exceeding API limits and to prevent the entire batch from failing due to one file
barstool.engineering
.

Dead‑letter queue: After maximum retries, move failed tasks to a dead‑letter queue for manual inspection and resolution.

Monitoring and alerting: Use metrics and logs to detect unusual error rates. Set up alerts on high failure rates, long queue lengths or repeated UploadFailed statuses.

Manual retry / self‑service: Provide an endpoint that allows the customer or support staff to manually retry uploads for documents in UploadFailed status. Manual retries should still honour idempotency and should not duplicate uploads.

7.3 Testing and validation
Unit tests: Validate the BFF logic (file validation, metadata persistence). Mock the cloud service and RFI API to test failure scenarios and retry logic.

Integration tests: Simulate network failures, slow responses and cloud outages. Verify that the background job handles retries correctly and does not lose data.

Load tests: Upload multiple files concurrently to ensure the system scales. Evaluate the effect of concurrency limits and batching on performance.

Security tests: Perform penetration tests on file uploads to ensure proper sanitisation and that malicious files cannot be executed. Verify encryption of data at rest and in transit.

8 Additional considerations
Data retention and compliance: Documents may contain personally identifiable information (PII). Implement retention policies, anonymisation where appropriate and secure deletion after the retention period. Ensure compliance with UAE regulations such as Dubai’s Data Protection Law.

Localization and accessibility: Ensure the UI supports multiple languages and is accessible to users with disabilities. Provide clear error messages when uploads fail.

Extensibility: Design the system so that new document categories can be added without code changes. Use configuration tables to define which categories are required and what validations apply.

9 Conclusion
This TSD defines a document upload service for the customer portal with a robust, asynchronous design. Documents are stored locally and later uploaded to a cloud service via an event‑driven background job. The resilience plan applies retry patterns with exponential backoff and jitter
dev.to
, idempotent operations
internetcomputer.org
, concurrency limits
barstool.engineering
 and proper logging
learn.microsoft.com
 to handle transient faults and ensure data integrity. With proper monitoring, security and regulatory compliance, the service will provide a reliable user experience even under adverse conditions.
